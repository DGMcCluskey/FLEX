# SoupX processing of Lung Flex data
```{r}
library(SoupX)
library(Seurat)
```

### set up directories and names of pools and samples
```{r}
flex_path <- "c:/Users/dan_m/OneDrive - University College London/UCL_Senior_Research_Fellow/FLEX/alignments_Jan26"

pool_ident <- c(
  "POMS_01Pool1LNSFunsort_G",
  "POMS_01Pool2LNSFFACSsort_G",
  "POMS_01Pool3LNCFunsort_G",
  "POMS_01Pool4LNCFFACSsort_G"
)

sample_ident <- c("BC001", "BC002", "BC003", "BC004")
```

### loop over each sample (within each pool), getting the droplets and counts tables, which are then paired into a soupchannel
### also get the clustering info generated by cellranger as this is said to improve soupx performance
### toc = counts, tod = droplets
```{r}
soup_channels <- list()

for (pool in pool_ident) {
  for (sample in sample_ident) {

    toc_path <- file.path(
      flex_path, pool,
      "outs/per_sample_outs", sample,
      "count/sample_filtered_feature_bc_matrix.h5"
    )

    tod_path <- file.path(
      flex_path, pool,
      "outs/per_sample_outs", sample,
      "count/sample_raw_feature_bc_matrix.h5"
    )

    clusters_path <- file.path(
      flex_path, pool,
      "outs/per_sample_outs", sample,
      "count/analysis/clustering/gene_expression_graphclust/clusters.csv"
    )

    if (!file.exists(toc_path) ||
        !file.exists(tod_path)) {
      message("Skipping missing: ", pool, " / ", sample)
      next
    }

    toc <- Read10X_h5(toc_path)
    tod <- Read10X_h5(tod_path)

    tod <- tod[row.names(toc),]

    sc <- SoupChannel(tod, toc, calcSoupProfile = FALSE)

    clusters <- read.csv(clusters_path)
    clusters <- setNames(clusters$Cluster, clusters$Barcode)

    sc <- setClusters(sc, clusters)
    sc <- estimateSoup(sc)

    key <- paste(pool, sample, sep = "_")
    soup_channels[[key]] <- sc
  }
}

```

### estimate contamination. using a tfidmin of 0.2 based on tutorial recommendation and the fact it works (apparently some numbers can fail?)
```{r}
soup_channels <- lapply(soup_channels, function(x) autoEstCont(x, tfidfMin = 0.2, forceAccept=TRUE))
```

### perfrom the adjustment
```{r}
out <- lapply(soup_channels, function(x) adjustCounts(x))
```

### look a genes that have been zeroed the most
```{r}
mostZeroed_per_sample <- lapply(names(out), function(samp) {
  sc <- soup_channels[[samp]]
  adj <- out[[samp]]
  
  # fraction of non-zero counts removed
  fracZeroed <- (rowSums(sc$toc > 0) - rowSums(adj > 0)) / rowSums(sc$toc > 0)
  
  # top 10 most zeroed genes
  tail(sort(fracZeroed), n = 10)
})

names(mostZeroed_per_sample) <- names(out)
mostZeroed_per_sample

```

### save adjusted counts as new h5 files
```{r}
lapply(names(out), function(samp) {
  # generate a unique file name per sample
  out_file <- file.path("./soupx/", paste0(samp, "_soupx.h5"))
  
  # write adjusted counts
  DropletUtils:::write10xCounts(
    out_file,
    out[[samp]],
    overwrite = TRUE,
    type = "HDF5"
  )
})
```

### plot histograms showing the shift in nUMI after adjustment to assess how many umis have actually been removed
```{r}
library(ggplot2)

samp <- "POMS_01Pool1LNSFunsort_G_BC004"  # pick one sample

toc <- soup_channels[[samp]]$toc
adj <- out[[samp]]

# total UMIs per cell before and after
df <- data.frame(
  nUMIs = c(colSums(toc), colSums(adj)),
  status = rep(c("Original", "Adjusted"), each = ncol(toc))
)

ggplot(df, aes(x = nUMIs, fill = status)) +
  geom_density(alpha = 0.5) +
  scale_x_log10() +
  ggtitle(paste("UMI distribution before vs after SoupX:", samp))
```
