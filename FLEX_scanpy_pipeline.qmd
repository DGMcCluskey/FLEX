---
title: "Untitled"
format: html
---

# Peforming the scanpy pipeline (QC, transformation, clustering, DR) on the FLEX lung data
## exploratory and advanced analysis will be done in a separate script for clarity

```{python}
import os
import re
import sys
import scanpy as sc
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
import anndata as ad
from scipy.stats import median_abs_deviation
```

```{python}
print(sys.executable)
```

### using Tim's code, define the oultiers in the data, using different metrics
```{python}
#Define outliers in metrics of adata. Based on the function from sc-best-practices.
# If nmads is set with the number of nmads to take, then the median absolute deviations method is used to calculate outliers.
# If, instead, max_ and min_val are set, then these are used to manually filter for outliers.
# Note that outliers are annotated as "metrics"_outlier in adata.obs, and are not removed.
# A dataframe is also returned of the metric/outlier stats, including how many cells are outliers and the max/min values used.
def is_outlier(adata,  
               scPrefix: str, 
               metrics: str, 
               nmads: int | None = None, 
               max_val: float | int | None = None,
               min_val: float | int | None = None):
    genotype_df = pd.DataFrame()
    for metric in metrics:
        M = adata.obs[metric]
        if nmads is not None:
            med_val = np.median(M)
            med_dev = median_abs_deviation(M)
            min_mad = med_val - nmads * med_dev
            max_mad = med_val + nmads * med_dev
        elif max_val is not None or min_val is not None :
            #Minimum and/or Maximum value set manually in function
            min_mad = min_val if min_val is not None else 0
            max_mad = max_val if max_val is not None else np.inf
            print(metric, 'min/max values have been manually set')

        print('Minimum/Maximum value of', 
              metric, 
              round(min_mad, ndigits = 2), 
              round(max_mad, ndigits = 2))
        #Annotate the outliers in the adata.obs dataframe.
        outlier = (M < min_mad) | ( max_mad < M )
        adata.obs[metric+'_outlier'] = outlier
        
        # #Make a dataframe of outlier stats for each metric and genotype/patient.
        # metric_genotype_df = pd.DataFrame()
        # for genotype in adata.obs.Genotype_ID.unique():
        #     gen_idx = adata.obs.Genotype_ID == genotype
        #     num_below = sum(M[gen_idx] < min_mad)
        #     num_above = sum(M[gen_idx] > max_mad)
        #     num_filt = sum(outlier[gen_idx])
        #     tot = sum(gen_idx)
        #     metric_genotype_df = pd.concat([ metric_genotype_df, 
        #                              pd.DataFrame({metric + '_minNum': num_below,
        #                                            metric + '_maxNum': num_above,
        #                                            metric + '_filtNum': num_filt,
        #                                            metric + '_minPerc': round(100*num_below/tot,2),
        #                                            metric + '_maxPerc': round(100*num_above/tot,2),
        #                                            metric + '_filtPerc': round(100*num_filt/tot,2),
        #                                            metric + '_min': round(min_mad,2) if min_mad > 0 else 0,
        #                                            metric + '_max': round(max_mad,2)},
        #                                           index = [ scPrefix + '_' + genotype ]) ],
        #                             axis = 0, join = "outer")
        # #Merge the outlier/genotype dataframes together. (TODO: I think this may be unnecessary, genotype_df is empty?)
        # genotype_df = genotype_df.join(metric_genotype_df, how = "outer")

        #Make a dataframe of outlier stats for each metric and pool.
        # Then merge the outlier/pool dataframes across the metrics provided.
        if metric == metrics[0]:
            pool_df = pd.DataFrame({metric + '_min': round(min_mad,2) if min_mad > 0 else 0,
                               metric + '_max': round(max_mad,2),
                               metric + '_min_filtCells': sum(M < min_mad),
                               metric + '_max_filtCells': sum(M > max_mad)},
                              index = [ scPrefix ])
        else:
            pool_df = pool_df.join(pd.DataFrame({metric + '_min': round(min_mad,2) if min_mad > 0 else 0,
                                       metric + '_max': round(max_mad,2),
                                       metric + '_min_filtCells': sum(M < min_mad),
                                       metric + '_max_filtCells': sum(M > max_mad)},
                                      index = [ scPrefix ]))
    
    return adata, pool_df
    #  genotype_df
```

# Prepare celltypist for later use
```{python}
import celltypist
from celltypist import models
```
```{python}
models.download_models(
    force_update=True, 
    model=["Cells_Fetal_Lung.pkl"]
)
model_foetal_lung = models.Model.load(model="Cells_Fetal_Lung.pkl")

# CellTypist 'control'
models.download_models(
    force_update=True, 
    model=["Human_IPF_Lung.pkl"]
)
model_adult_lung = models.Model.load(model="Human_IPF_Lung.pkl")
```
```{python}
#Setting majority voting result as the cell label, 
# the predicted label (for each cell, without clustering majority voting) will be the 'predict'
def join_celltypist_df(celltypist_adata_obs, 
                       input_adata_obs, 
                       new_col_suffix):
    """Join relevant columns of the celltypist dataframe with the adata.obs input"""
    import pandas as pd
    celltypist_df = pd.DataFrame({"celltypist_label_" + new_col_suffix : celltypist_adata_obs["majority_voting"],
                                 "celltypist_predict_" + new_col_suffix : celltypist_adata_obs["predicted_labels"],
                                 "celltypist_conf_score_" + new_col_suffix : celltypist_adata_obs["conf_score"]})
    return input_adata_obs.join(celltypist_df)
```

```{python}
soupx_path = "c:/Users/dan_m/OneDrive - University College London/UCL_Senior_Research_Fellow/FLEX/soupx/"

pool_list = [
  "POMS_01Pool1LNSFunsort_G",
  "POMS_01Pool2LNSFFACSsort_G",
  "POMS_01Pool3LNCFunsort_G",
  "POMS_01Pool4LNCFFACSsort_G"
  ]

sample_list = ["BC001", "BC002", "BC003", "BC004"]
```

```{python}
flex_data = []
for pool_id in pool_list:
    print(pool_id)
    for sample_id in sample_list:
        print(sample_id)
        h5_path = soupx_path + pool_id + "_" + sample_id + '_soupx.h5'
        h5 = sc.read_10x_h5(h5_path)
        h5.obs['sample_id'] = sample_id
        h5.obs['pool_id'] = pool_id
        h5.obs_names = h5.obs_names + '_' + sample_id + pool_id
        print(h5.shape)
        flex_data.append(h5)
```

```{python}
for flex in flex_data:
    #Annotate given classes of genes (Genes are saved in the .vars section of flex)
    # mitochondrial genes
    flex.var["mt"] = flex.var_names.str.startswith("MT-")
    # hemoglobin genes.
    flex.var["hb"] = flex.var_names.str.contains(("^HB[^(P)]"))
    # Calculate metrics for these genes
    sc.pp.calculate_qc_metrics(
        flex, qc_vars=["mt", "hb"], inplace=True, percent_top=[20], log1p=True
    )
```

```{python}
flex_outlier_list = []
for flex in flex_data:
    sample_id = flex.obs['sample_id'][0]
    print(sample_id)
    # Identify outliers with nmads = 5 (a normal amount) for pcr_counts_mt
    flex_outlier, pool_df = is_outlier(flex, 
                                        metrics = ['pct_counts_mt'], 
                                        # nmads = 3,
                                        min_val = 0,
                                        max_val = 50, 
                                        scPrefix=sample_id)
    # Identify outliers for total_counts and n_genes_by_counts with 99 percentile
    flex_outlier, pool_df2 = is_outlier(flex_outlier, 
                                        metrics = ['total_counts',], 
                                        max_val = np.percentile(flex_outlier.obs['total_counts'], 99.9), 
                                        min_val = 10,
                                        scPrefix=sample_id)
    flex_outlier, pool_df3 = is_outlier(flex_outlier, 
                                        metrics = ['n_genes_by_counts',], 
                                        max_val = np.percentile(flex_outlier.obs['n_genes_by_counts'], 99.9), 
                                        min_val = 10,
                                        scPrefix=sample_id)
    pool_df = pool_df.join(pool_df2).join(pool_df3)
    pool_df['pool_id'] = flex_outlier.obs['pool_id'][0]
    #Annotate the cells which are an outlier by any metric by getting all outlier cols and applying 'sum' across each row.
    outlier_columns = [i for i in flex_outlier.obs.columns if re.search("_outlier$",i) is not None]
    flex_outlier.obs['outlier_any'] = flex_outlier.obs.loc[:, outlier_columns].apply(np.sum, axis = 1) > 0
    flex_outlier.uns['pool_df'] = pool_df
    print(flex_outlier.obs.value_counts(['total_counts_outlier', 'n_genes_by_counts_outlier', 'pct_counts_mt_outlier']))
    flex_outlier_list.append(flex_outlier)
```


# MERGE SAMPLES INTO ONE OBJECT
```{python}
from functools import reduce
#Merge the AnnData objects together.
flex_adata = reduce(lambda left, right: ad.concat([left, right], axis = 'obs', join = 'outer'), flex_outlier_list)
flex_adata
```

### cleaning up sample and pool names
```{python}
pool_dict = {
    "POMS_01Pool1LNSFunsort_G" : "snapfrozen_unsorted",
    "POMS_01Pool2LNSFFACSsort_G" : "snapfrozen_sorted",
    "POMS_01Pool3LNCFunsort_G" : "chopfix_unsorted",
    "POMS_01Pool4LNCFFACSsort_G" : "chopfix_sorted"
}
flex_adata.obs["pool_id"] = flex_adata.obs["pool_id"].map(pool_dict)
flex_adata.obs["donor"] = flex_adata.obs["sample_id"]
flex_adata.obs["sample_id"] = (flex_adata.obs["donor"].astype(str) + "_" + flex_adata.obs["pool_id"].astype(str))
flex_adata.obs
```

### save object
```{python}
flex_adata.write("flex_adata_combined_pre_qc.h5ad")
```

# DOUBLET REMOVAL
### see doublet removal script

### after doublet removal script has been run, load the data back in for QC
```{python}
flex_adata = sc.read_h5ad("flex_data_doublets_identified.h5ad")
flex_adata
```

# QUALITY CONTROL
```{python}
for s in flex_adata.obs["sample_id"].unique():
    sc.pl.scatter(
        flex_adata[flex_adata.obs["sample_id"] == s],
        x="total_counts",
        y="n_genes_by_counts",
        color="pct_counts_mt",
        title=f"QC: {s}",
        size=5
    )
```


### plotting number of cells per sample and the percentage mito genes
```{python}

# Prepare figure: 2 rows, 1 column, share x-axis
fig, axes = plt.subplots(3, 1, figsize=(8, 10), sharex=True)

# Top violin: pct_counts_mt
sc.pl.violin(
    flex_adata,
    keys=["pct_counts_mt"],
    groupby="sample_id",
    stripplot=False,
    rotation=90,
    palette=["mediumseagreen", "darkorchid", "orange", "grey"],
    ax=axes[0],
    show=False
)
axes[0].set_title("Mitochondrial % per sample")
axes[0].tick_params(axis="x", labelbottom=False)  # remove x labels

# Bottom violin: n_genes_by_counts
sc.pl.violin(
    flex_adata,
    keys=["pct_counts_hb"],
    groupby="sample_id",
    stripplot=False,
    rotation=90,
    palette=["mediumseagreen", "darkorchid", "orange", "grey"],
    ax=axes[1],
    show=False
)
axes[1].set_title("Haemoglobin % per sample")

sc.pl.violin(
    flex_adata,
    keys=["n_genes_by_counts"],
    groupby="sample_id",
    stripplot=False,
    rotation=90,
    palette=["mediumseagreen", "darkorchid", "orange", "grey"],
    ax=axes[2],
    show=False
)
axes[2].set_title("Genes per cell per sample")
# Optional: bold + rotate bottom x-axis labels
plt.setp(
    axes[2].get_xticklabels(),
    rotation=90,
    fontsize=14,
    fontweight="bold"
)

plt.tight_layout()
plt.savefig("qc_summary.png", dpi=300, bbox_inches="tight")
plt.show()

```

```{python}
cells_per_sample = flex_adata.obs['sample_id'].value_counts()
plt.figure()
sns.barplot(
    x=cells_per_sample.index,
    y=cells_per_sample.values
)
plt.xticks(rotation=90)
plt.tight_layout()
plt.savefig("total_counts.png", dpi=300, bbox_inches="tight")
plt.show()
```

```{python}
pd.crosstab(flex_adata.obs['sample_id'], [
    flex_adata.obs['outlier_any'],
    flex_adata.obs['pct_counts_mt'] < 25,
    (flex_adata.obs['total_counts'] > 10),
    (flex_adata.obs['n_genes_by_counts'] > 10),
    flex_adata.obs['pct_counts_hb'] < 10])
```

```{python}
flex_adata.obs.value_counts(['total_counts_outlier', 'n_genes_by_counts_outlier', 'pct_counts_mt_outlier'])
```

# FILTERING
### removing cells with more than 25% mito counts, less than 10 counts and less than 10 unique genes
```{python}
flex_adata = flex_adata[(flex_adata.obs['pct_counts_mt'] < 25) & 
    (flex_adata.obs['total_counts'] > 10) & 
    (flex_adata.obs['n_genes_by_counts'] > 10) &
    (flex_adata.obs['pct_counts_hb'] < 10), :]
```

### check after filtering
```{python}
sc.pl.violin(flex_adata, keys = ['total_counts', 'n_genes_by_counts', 'pct_counts_mt', "pct_counts_hb"], groupby = 'sample_id', rotation = 90, multi_panel = True)
```

# NORMALISATION
### due to this object being transferred into R as a sce, i had to make a counts layer in there. X is now empty because of that, so need to replace and then make counts again like normal
```{python}
flex_adata.X = flex_adata.layers['counts']
flex_adata.layers['counts'] = flex_adata.X.copy()
sc.pp.normalize_total(flex_adata, target_sum=1e4)
sc.pp.log1p(flex_adata)
flex_adata.layers['logcounts'] = flex_adata.X.copy()
```
```{python}
plt.figure()
sns.histplot(
        flex_adata.layers['counts'].sum(1), bins=500, kde=False
    )
plt.show()

plt.figure()
sns.histplot(
        flex_adata.layers['logcounts'].sum(1), bins=500, kde=False
    )
plt.show()
```

# EMBEDDING
### run this without batch correction first to see how strong existin effects are
### first calculate HVGs
```{python}
sc.pp.highly_variable_genes(
    flex_adata, 
    n_top_genes=2000, 
    flavor="cell_ranger", 
    batch_key='sample_id', 
    layer = 'logcounts',
    subset = False
)
```

### run PCA
```{python}
sc.pp.pca(flex_adata, svd_solver="arpack", use_highly_variable=True)
sc.pl.pca_variance_ratio(flex_adata, n_pcs=50, log=True)
```

```{python}
plt.figure(figsize=[8,5])
sc.pl.pca(
    flex_adata, legend_loc="best",
    color=["donor", "pool_id", "pct_counts_mt"],
    ncols=3,
    size=2,
)
plt.tight_layout()
plt.savefig("PCA_inspection.png", dpi=300, bbox_inches="tight")
plt.show()
```

```{python}
sc.pp.neighbors(flex_adata, n_pcs=30)
sc.tl.umap(flex_adata, random_state=2025)
```

```{python}
plt.figure(figsize=(20,15))
sc.pl.umap(flex_adata, color=["pool_id", "donor"], wspace=0.5,show=True, size = 2)
plt.tight_layout()
plt.savefig("UMAP_uncorrected.png",dpi=300)
```

### batch correction definately needed

# BACTH CORRECTION
### will use scVI as successful in the past and well regarded
### batch aware hvgs already generated before so can go striaght to setting up model
```{python}
flex_hvg = flex_adata[:, flex_adata.var["highly_variable"]].copy()
flex_hvg
```

```{python}
import scvi
scvi.model.SCVI.setup_anndata(flex_hvg, layer="counts", batch_key="sample_id")
flex_hvg
model_scvi = scvi.model.SCVI(flex_hvg)
model_scvi
model_scvi.view_anndata_setup()
```
```{python}
max_epochs_scvi = np.min([round((20000 / flex_adata.n_obs) * 400), 400])
max_epochs_scvi
```

```{python}
model_scvi.train()
```